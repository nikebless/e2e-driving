{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50660f1c",
   "metadata": {},
   "source": [
    "# Visualize energy landscape\n",
    "\n",
    "1. Pull a model from W&B\n",
    "2. Convert the model to ONNX (scripts/pt_to_onnx.py)\n",
    "3. Run this notebook\n",
    "4. Run visualization (scripts/visualize_energy.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef447d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "import onnxruntime as ort\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from dataloading.nvidia import NvidiaCropWide, Normalize, NvidiaDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0804cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_energy(model, x, y):\n",
    "    inputs = {'x': x, 'y': y}\n",
    "    return model.run(None, inputs)[0].squeeze()\n",
    "\n",
    "def get_dataset_energy(model, dataloader, n_samples=256, bound=1.5):\n",
    "    all_energies = []\n",
    "    progress_bar = tqdm(total=len(dataloader), smoothing=0)\n",
    "    batch_size = dataloader.batch_size\n",
    "\n",
    "    samples = np.linspace(-bound, bound, num=n_samples, dtype=np.float32).reshape(1, -1).repeat(batch_size, axis=0)\n",
    "    samples = np.expand_dims(samples, axis=-1)\n",
    "\n",
    "    for i, (input, _, __) in enumerate(dataloader):\n",
    "\n",
    "        if input['image'].shape[0] != batch_size:\n",
    "            print(f'Dropping batch with {input[\"image\"].shape[0]} samples')\n",
    "            continue\n",
    "\n",
    "        inputs = input['image'].cpu().numpy()\n",
    "        energy = get_energy(model, inputs, samples)\n",
    "\n",
    "        all_energies.extend(energy)\n",
    "        progress_bar.update(1)\n",
    "\n",
    "\n",
    "    result = np.array(all_energies)\n",
    "    return result, samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "718be735",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "/onnxruntime_src/onnxruntime/core/platform/posix/env.cc:183 onnxruntime::{anonymous}::PosixThread::PosixThread(const char*, int, unsigned int (*)(int, Eigen::ThreadPoolInterface*), Eigen::ThreadPoolInterface*, const onnxruntime::ThreadOptions&) pthread_setaffinity_np failed, error code: 11 error msg: Resource temporarily unavailable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model = ort.InferenceSession(\"../_models/ebm-regularized-v1-energy.onnx\", providers=['CUDAExecutionProvider'])\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mort\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInferenceSession\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../_models/ebm-regularized-v1-energy.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/itn2/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:335\u001b[0m, in \u001b[0;36mInferenceSession.__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m disabled_optimizers \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_inference_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisabled_optimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "File \u001b[0;32m~/.conda/envs/itn2/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:368\u001b[0m, in \u001b[0;36mInferenceSession._create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    366\u001b[0m session_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess_options \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess_options \u001b[38;5;28;01melse\u001b[39;00m C\u001b[38;5;241m.\u001b[39mget_default_session_options()\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_path:\n\u001b[0;32m--> 368\u001b[0m     sess \u001b[38;5;241m=\u001b[39m \u001b[43mC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInferenceSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_config_from_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     sess \u001b[38;5;241m=\u001b[39m C\u001b[38;5;241m.\u001b[39mInferenceSession(session_options, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_bytes, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_config_from_model)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: /onnxruntime_src/onnxruntime/core/platform/posix/env.cc:183 onnxruntime::{anonymous}::PosixThread::PosixThread(const char*, int, unsigned int (*)(int, Eigen::ThreadPoolInterface*), Eigen::ThreadPoolInterface*, const onnxruntime::ThreadOptions&) pthread_setaffinity_np failed, error code: 11 error msg: Resource temporarily unavailable\n"
     ]
    }
   ],
   "source": [
    "# model = ort.InferenceSession(\"../_models/ebm-regularized-v1-energy.onnx\", providers=['CUDAExecutionProvider'])\n",
    "model = ort.InferenceSession(\"../_models/ebm-regularized-v1-energy.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e27b2cd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/gpfs/space/home/mykyta/e2e-driving/notebooks/create_drive_energy_landscape.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhpc/gpfs/space/home/mykyta/e2e-driving/notebooks/create_drive_energy_landscape.ipynb#ch0000004vscode-remote?line=0'>1</a>\u001b[0m root_path \u001b[39m=\u001b[39m Path(\u001b[39m\"\u001b[39m\u001b[39m/data/Bolt/drives-nikita-thesis/\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhpc/gpfs/space/home/mykyta/e2e-driving/notebooks/create_drive_energy_landscape.ipynb#ch0000004vscode-remote?line=1'>2</a>\u001b[0m valid_paths \u001b[39m=\u001b[39m [root_path \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m2022-07-11-15-22-50_test_vahi_ibc_dfo_drop_frames\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bhpc/gpfs/space/home/mykyta/e2e-driving/notebooks/create_drive_energy_landscape.ipynb#ch0000004vscode-remote?line=3'>4</a>\u001b[0m _, samples \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_inputs()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhpc/gpfs/space/home/mykyta/e2e-driving/notebooks/create_drive_energy_landscape.ipynb#ch0000004vscode-remote?line=4'>5</a>\u001b[0m batch_size, n_samples, _ \u001b[39m=\u001b[39m samples\u001b[39m.\u001b[39mshape\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhpc/gpfs/space/home/mykyta/e2e-driving/notebooks/create_drive_energy_landscape.ipynb#ch0000004vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mbatch_size:\u001b[39m\u001b[39m'\u001b[39m, batch_size, \u001b[39m'\u001b[39m\u001b[39mn_samples:\u001b[39m\u001b[39m'\u001b[39m, n_samples)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "root_path = Path(\"/data/Bolt/drives-nikita-thesis/\")\n",
    "valid_paths = [root_path / \"2022-07-11-15-22-50_test_vahi_ibc_dfo_drop_frames\"]\n",
    "\n",
    "_, samples = model.get_inputs()\n",
    "batch_size, n_samples, _ = samples.shape\n",
    "\n",
    "print('batch_size:', batch_size, 'n_samples:', n_samples)\n",
    "\n",
    "# TODO: try CV2 resize as done during inference\n",
    "tr = transforms.Compose([NvidiaCropWide(), Normalize()])\n",
    "inference_set = NvidiaDataset(valid_paths, transform=tr)\n",
    "\n",
    "inference_loader = torch.utils.data.DataLoader(inference_set, batch_size=batch_size, shuffle=False,\n",
    "                                         num_workers=1, pin_memory=False, persistent_workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4491e8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3ea99213ce4cf5853ca53e6661db9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping batch with 16 samples\n"
     ]
    }
   ],
   "source": [
    "energy, samples = get_dataset_energy(model, inference_loader, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "519265ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('energy_valley.npy', energy)\n",
    "np.save('samples.npy', samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a9f4354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(18976, 1024), (1024, 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[energy.shape, samples.shape]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('e2e')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "322c5c4facabdc6bcc8c78b7959ccdee3ccc8c0dc306e4585416789305ea23e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
