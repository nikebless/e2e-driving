{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('/home/nikita/e2e-driving')\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import math\n",
    "\n",
    "from ibc import optimizers\n",
    "from dataloading.nvidia import NvidiaDataset\n",
    "from metrics.metrics import calculate_open_loop_metrics\n",
    "from pilotnet import PilotnetEBM\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikita/miniconda3/envs/e2e/lib/python3.9/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  /opt/conda/conda-bld/pytorch_1646756402876/work/c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    inference_times = []\n",
    "    progress_bar = tqdm(total=len(dataloader), smoothing=0)\n",
    "\n",
    "    epoch_mae = 0.0\n",
    "    epoch_entropy = 0.0\n",
    "    ask_batch_timestamp = time.time()\n",
    "    for i, (input, target, _) in enumerate(dataloader):\n",
    "        recv_batch_timestap = time.time()\n",
    "\n",
    "        inputs = input['image'].to(device)\n",
    "        target = target.to(device, torch.float32)\n",
    "\n",
    "        inference_start = time.perf_counter()\n",
    "        preds, energy = model(inputs)\n",
    "        inference_end = time.perf_counter()\n",
    "\n",
    "        inference_time = inference_end - inference_start\n",
    "        inference_times.append(inference_time)\n",
    "\n",
    "        mae = F.l1_loss(preds, target.view(-1, 1))\n",
    "        mae_degrees = math.degrees(mae.item())\n",
    "        epoch_mae += mae_degrees\n",
    "\n",
    "        entropy = Categorical(F.softmax(-energy, dim=-1)).entropy().mean() / math.log(energy.shape[-1])\n",
    "        epoch_entropy += entropy.item()\n",
    "\n",
    "        all_predictions.extend(preds.cpu().squeeze().numpy())\n",
    "\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_description(f'MAE: {(epoch_mae / (i + 1)):.4f} | Entropy: {(epoch_entropy / (i + 1)):.4f}')\n",
    "\n",
    "        ask_batch_timestamp = time.time()\n",
    "\n",
    "    avg_mae = epoch_mae / len(dataloader)\n",
    "    avg_entropy = epoch_entropy / len(dataloader)\n",
    "    result = np.array(all_predictions)\n",
    "    return avg_mae, avg_entropy, result\n",
    "\n",
    "\n",
    "def calculate_metrics(fps, predictions, valid_loader):\n",
    "    '''For steering angle only.'''\n",
    "\n",
    "    frames_df = valid_loader.dataset.frames\n",
    "    true_steering_angles = frames_df.steering_angle.to_numpy()\n",
    "    metrics = calculate_open_loop_metrics(predictions, true_steering_angles, fps=fps)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "class VelocityModel:\n",
    "    def __init__(self, positions_parquet='positions.parquet', vector_velocity=30):\n",
    "        self.vector_velocity = vector_velocity\n",
    "        self.positions_df = pd.read_parquet(positions_parquet)\n",
    "        self.tree = BallTree(self.positions_df[[\"position_x\", \"position_y\", \"position_x2\", \"position_y2\"]])\n",
    "\n",
    "    def find_closest_position(self, x, y, yaw):\n",
    "        x2 = x + (self.vector_velocity * np.cos(yaw))\n",
    "        y2 = y + (self.vector_velocity * np.sin(yaw))\n",
    "\n",
    "        closest = self.tree.query([[x, y, x2, y2]])\n",
    "        distance = closest[0][0][0]\n",
    "        index = closest[1][0][0]\n",
    "        return self.positions_df.iloc[index], distance\n",
    "\n",
    "def trim_human_datasets_to_auto_datasets(human_drive_ds, forward_auto_frames, back_auto_frames):\n",
    "    velmodel = VelocityModel('~/ros-e2e-workspace/src/e2e_platform/config/speed_models/summer2021-positions.parquet')\n",
    "\n",
    "    forward_start = forward_auto_frames.iloc[0]\n",
    "    forward_end = forward_auto_frames.iloc[-1]\n",
    "    back_start = back_auto_frames.iloc[0]\n",
    "    back_end = back_auto_frames.iloc[-1]\n",
    "\n",
    "    forward_start_frame, forward_start_dist = velmodel.find_closest_position(forward_start['position_x'], forward_start['position_y'], forward_start['yaw'])\n",
    "    forward_end_frame, forward_end_dist = velmodel.find_closest_position(forward_end['position_x'], forward_end['position_y'], forward_end['yaw'])\n",
    "    back_start_frame, back_start_dist = velmodel.find_closest_position(back_start['position_x'], back_start['position_y'], back_start['yaw'])\n",
    "    back_end_frame, back_end_dist = velmodel.find_closest_position(back_end['position_x'], back_end['position_y'], back_end['yaw'])\n",
    "\n",
    "    # print('forward start:', forward_start_dist, forward_start_frame.name)\n",
    "    # print('forward end:', forward_end_dist, forward_end_frame.name)\n",
    "    # print('back start:', back_start_dist, back_start_frame.name)\n",
    "    # print('back end:', back_end_dist, back_end_frame.name)\n",
    "\n",
    "    human_indices = human_drive_ds.frames.index.to_numpy()\n",
    "    human_indices_current = human_indices[:-1]\n",
    "    human_indices_next = human_indices[1:]\n",
    "    change_of_direction_idx = (human_indices_next < human_indices_current).nonzero()[0].item()\n",
    "\n",
    "    forward_filtered = human_drive_ds.frames.iloc[forward_start_frame.name:forward_end_frame.name]\n",
    "    back_filtered = human_drive_ds.frames.iloc[change_of_direction_idx+back_start_frame.name:change_of_direction_idx+back_end_frame.name]\n",
    "\n",
    "    merged = pd.concat([forward_filtered, back_filtered], ignore_index=True).reset_index(drop=True)\n",
    "    human_drive_ds.frames = merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/Bolt/dataset-new-big/summer2021/2021-10-26-10-49-06_e2e_rec_ss20_elva: length=33045, filtered=0\n",
      "/data/Bolt/dataset-new-big/summer2021/2021-10-26-11-08-59_e2e_rec_ss20_elva_back: length=33281, filtered=0\n"
     ]
    }
   ],
   "source": [
    "human_drive = Path('/data/Bolt/dataset-new-big/summer2021/2021-10-26-10-49-06_e2e_rec_ss20_elva')\n",
    "human_drive_back = Path('/data/Bolt/dataset-new-big/summer2021/2021-10-26-11-08-59_e2e_rec_ss20_elva_back')\n",
    "human_drive_ds = NvidiaDataset([human_drive, human_drive_back])\n",
    "\n",
    "# trim human dataset to auto dataset\n",
    "forward_frames = pd.read_csv('/data/Bolt/drives-nikita-thesis/2022-08-04-17-33-33_elva_forward_ebm_regularized_v3/nvidia_frames.csv')\n",
    "back_frames = pd.read_csv('/data/Bolt/drives-nikita-thesis/2022-08-04-17-21-58_elva_back_ebm_regularized_v3/nvidia_frames.csv')\n",
    "\n",
    "trim_human_datasets_to_auto_datasets(human_drive_ds, forward_frames, back_frames)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(human_drive_ds.frames, batch_size=256, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model_path = '/home/nikita/e2e-driving/models/20220618185552_steering-angle/last.pt'\n",
    "\n",
    "def evaluate_model(constant_actions=False, **kwargs):\n",
    "  model = PilotnetEBM()\n",
    "  inference_model = optimizers.DFOptimizerConst if constant_actions else optimizers.DFOptimizer\n",
    "  model = inference_model(model, optimizers.DerivativeFreeConfig(**kwargs))\n",
    "  model.load_state_dict(torch.load(pt_model_path))\n",
    "  model.to(device)\n",
    "  mae, entropy, preds = evaluate(model, valid_loader)\n",
    "\n",
    "  return mae, entropy, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.9315)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(torch.tensor(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 68, 264])\n"
     ]
    }
   ],
   "source": [
    "inputs = iter(valid_loader).next()[0]['image'][0].unsqueeze(0).to(device)\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:inference_samples is not equal to train_samples, which will likely cause poor performance when using constant samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running experiment 1/1. samples: 1024, iters: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9430a7487f2e4639a39ba1e490055a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment metrics:\n",
      "\"{'mae': 8.361593943192089, 'rmse': 33.65489972678105, 'max': 921.8890671983361, 'whiteness': 634.46564, 'expert_whiteness': 25.61257234059799, 'left_mae': 42.129001539884996, 'straight_mae': 5.378298346175109, 'right_mae': 78.43601723044296, 'entropy': 0.4784948651960722}\"\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import json\n",
    "import wandb\n",
    "\n",
    "fps = 30\n",
    "\n",
    "samples = [1024]\n",
    "iters = [0]\n",
    "constant_actions = [True]\n",
    "\n",
    "run_hparams = list(itertools.product(samples, iters, constant_actions))\n",
    "\n",
    "for idx, (samples, iters, constant_actions) in enumerate(run_hparams):\n",
    "    # wandb.init(project=\"ibc-tuning\", name=f'{samples}s{iters}it', config={\"samples\": samples, \"iters\": iters, \"model_path\": pt_model_path, \"constant_actions\": constant_actions})\n",
    "\n",
    "    print(f'running experiment {idx+1}/{len(run_hparams)}. samples: {samples}, iters: {iters}')\n",
    "    mae, entropy, preds = evaluate_model(constant_actions=constant_actions, inference_samples=samples, iters=iters)\n",
    "    metrics = calculate_metrics(fps, preds, valid_loader)\n",
    "    metrics[\"entropy\"] = entropy\n",
    "    # wandb.log(metrics)\n",
    "    print('experiment metrics:')\n",
    "    print(json.dumps(str(metrics), indent=2))\n",
    "    print()\n",
    "    # wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('e2e')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "322c5c4facabdc6bcc8c78b7959ccdee3ccc8c0dc306e4585416789305ea23e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
